{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VrHdzRQJ54fD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.5.8-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m740.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.18.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting unsloth_zoo>=2025.5.10 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.5.10-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Using cached torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.30-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Using cached triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from unsloth) (25.0)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.22-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
            "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tqdm (from unsloth)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: psutil in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from unsloth) (7.0.0)\n",
            "Collecting wheel>=0.42.0 (from unsloth)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from unsloth) (2.2.6)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting huggingface_hub (from unsloth)\n",
            "  Downloading huggingface_hub-0.32.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting diffusers (from unsloth)\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pyyaml (from accelerate)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.12.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub->unsloth)\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting setuptools (from torch>=2.4.0->unsloth)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.4.0->unsloth)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.4.0->unsloth)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n",
            "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.5.10->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pillow (from unsloth_zoo>=2025.5.10->unsloth)\n",
            "  Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.5.10->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting importlib-metadata (from diffusers->unsloth)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
            "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
            "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/phuc/project/Fense_System/env/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth) (2.19.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.4.0->unsloth)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata->diffusers->unsloth)\n",
            "  Downloading zipp-3.22.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.4.0->unsloth)\n",
            "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading unsloth-2025.5.8-py3-none-any.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.6/275.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.18.0-py3-none-any.whl (366 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.3/366.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hUsing cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
            "Using cached triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading unsloth_zoo-2025.5.10-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.7/145.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Downloading xformers-0.0.30-cp312-cp312-manylinux_2_28_x86_64.whl (31.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.22-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading aiohttp-3.12.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
            "Using cached yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
            "Downloading zipp-3.22.0-py3-none-any.whl (9.8 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: sentencepiece, nvidia-cusparselt-cu12, mpmath, zipp, xxhash, wheel, urllib3, typing-extensions, tqdm, sympy, shtab, setuptools, safetensors, regex, pyyaml, python-dotenv, pyarrow, protobuf, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, msgspec, mdurl, MarkupSafe, idna, hf-xet, hf_transfer, fsspec, frozenlist, filelock, docstring-parser, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, typeguard, triton, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jinja2, importlib-metadata, dotenv, aiosignal, rich, nvidia-cusolver-cu12, huggingface_hub, aiohttp, tyro, torch, tokenizers, diffusers, xformers, transformers, torchvision, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
            "Successfully installed MarkupSafe-3.0.2 accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.3 aiosignal-1.3.2 attrs-25.3.0 bitsandbytes-0.46.0 certifi-2025.4.26 charset-normalizer-3.4.2 cut_cross_entropy-25.1.1 datasets-3.6.0 diffusers-0.33.1 dill-0.3.8 docstring-parser-0.16 dotenv-0.9.9 filelock-3.18.0 frozenlist-1.6.0 fsspec-2025.3.0 hf-xet-1.1.2 hf_transfer-0.1.9 huggingface_hub-0.32.2 idna-3.10 importlib-metadata-8.7.0 jinja2-3.1.6 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 msgspec-0.19.0 multidict-6.4.4 multiprocess-0.70.16 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 peft-0.15.2 pillow-11.2.1 propcache-0.3.1 protobuf-3.20.3 pyarrow-20.0.0 python-dotenv-1.1.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rich-14.0.0 safetensors-0.5.3 sentencepiece-0.2.0 setuptools-80.9.0 shtab-1.7.2 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 torchvision-0.22.0 tqdm-4.67.1 transformers-4.52.3 triton-3.3.0 trl-0.18.0 typeguard-4.4.2 typing-extensions-4.13.2 tyro-0.9.22 unsloth-2025.5.8 unsloth_zoo-2025.5.10 urllib3-2.4.0 wheel-0.45.1 xformers-0.0.30 xxhash-3.5.0 yarl-1.20.0 zipp-3.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv unsloth trl accelerate bitsandbytes peft transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "xzVH9_RUL8N0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phuc/project/Fense_System/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 3050 Laptop GPU'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxXnvoP0xqF6"
      },
      "source": [
        "## CHECK URL, MAIL, PHONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QFRxBw9Vo4T"
      },
      "outputs": [],
      "source": [
        "VT_API_KEY=''\n",
        "ABSTRACT_EMAIL_API=''\n",
        "ABSTRACT_PHONE_API=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9kJjMljxuKC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "SUSPICIOUS_COUNTRIES = {\"Cambodia\", \"Nigeria\", \"Pakistan\", \"Afghanistan\", \"North Korea\"}\n",
        "\n",
        "def check_url_virustotal(url):\n",
        "    api_key = VT_API_KEY\n",
        "    url_id = base64.urlsafe_b64encode(url.encode()).decode().strip(\"=\")\n",
        "    vt_url = f\"https://www.virustotal.com/api/v3/urls/{url_id}\"\n",
        "\n",
        "    headers = {\n",
        "        \"x-apikey\": api_key\n",
        "    }\n",
        "\n",
        "    response = requests.get(vt_url, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "def parse_vt_result_for_display(vt_json):\n",
        "    try:\n",
        "        data = vt_json[\"data\"][\"attributes\"]\n",
        "        stats = data[\"last_analysis_stats\"]\n",
        "\n",
        "        url = data.get(\"last_final_url\", data.get(\"url\", \"\"))\n",
        "\n",
        "        harmless = stats.get(\"harmless\", 0)\n",
        "        malicious = stats.get(\"malicious\", 0)\n",
        "        suspicious = stats.get(\"suspicious\", 0)\n",
        "        undetected = stats.get(\"undetected\", 0)\n",
        "\n",
        "        # Đánh giá tổng quát\n",
        "        if malicious > 0:\n",
        "            overall = \"Nguy hiểm\"\n",
        "        elif suspicious > 0:\n",
        "            overall = \"Có thể đáng ngờ\"\n",
        "        else:\n",
        "            overall = \"An toàn\"\n",
        "\n",
        "        results = {\n",
        "            \"url\": url,\n",
        "            \"harmless\": harmless,\n",
        "            \"malicious\": malicious,\n",
        "            \"suspicious\": suspicious,\n",
        "            \"undetected\": undetected,\n",
        "            \"overall\": overall\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": f\"Không thể phân tích dữ liệu VirusTotal: {e}\"\n",
        "        }\n",
        "\n",
        "def check_email_validity(email):\n",
        "    api_key = ABSTRACT_EMAIL_API\n",
        "    url = \"https://emailvalidation.abstractapi.com/v1/\"\n",
        "    params = {\n",
        "        \"api_key\": api_key,\n",
        "        \"email\": email\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def parse_email_result(result):\n",
        "    try:\n",
        "        email = result.get(\"email\", \"N/A\")\n",
        "        deliverability = result.get(\"deliverability\", \"UNKNOWN\")\n",
        "        is_format_valid = result[\"is_valid_format\"][\"value\"]\n",
        "        is_smtp_valid = result[\"is_smtp_valid\"][\"value\"]\n",
        "        is_mx_found = result[\"is_mx_found\"][\"value\"]\n",
        "        is_free = result[\"is_free_email\"][\"value\"]\n",
        "        is_disposable = result[\"is_disposable_email\"][\"value\"]\n",
        "        is_role = result[\"is_role_email\"][\"value\"]\n",
        "\n",
        "        # Tổng kết hợp lệ\n",
        "        is_valid = all([\n",
        "            is_format_valid,\n",
        "            is_smtp_valid,\n",
        "            is_mx_found,\n",
        "            deliverability == \"DELIVERABLE\"\n",
        "        ])\n",
        "\n",
        "        result_dict = {\n",
        "            \"email\": email,\n",
        "            \"valid\": is_valid,\n",
        "            \"deliverability\": deliverability,\n",
        "            \"is_format_valid\": is_format_valid,\n",
        "            \"is_smtp_valid\": is_smtp_valid,\n",
        "            \"is_mx_found\": is_mx_found,\n",
        "            \"is_free_email\": is_free,\n",
        "            \"is_disposable_email\": is_disposable,\n",
        "            \"is_role_email\": is_role,\n",
        "            \"conclusion\": (\n",
        "                \"Hợp lệ (SMTP & MX tồn tại)\" if is_valid else\n",
        "                \"Không hợp lệ hoặc không gửi được\"\n",
        "            ),\n",
        "            \"description\": {\n",
        "                \"type\": \"Miễn phí\" if is_free else \"Domain riêng\",\n",
        "                \"spam\": \"Tạm thời / spam\" if is_disposable else \"Không phải spam\",\n",
        "                \"role\": \"Đại diện tổ chức\" if is_role else \"Email cá nhân\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return result_dict\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": f\"Không thể phân tích kết quả email: {e}\"\n",
        "        }\n",
        "\n",
        "def normalize_phone_vn(phone: str) -> str:\n",
        "    if phone.startswith(\"0\") and len(phone) == 10:\n",
        "        return \"+84\" + phone[1:]\n",
        "    elif phone.startswith(\"+84\"):\n",
        "        return phone\n",
        "    return phone\n",
        "\n",
        "def check_phone_validity(phone):\n",
        "    api_key = ABSTRACT_PHONE_API\n",
        "    if not api_key:\n",
        "        raise ValueError(\"❌ ABSTRACT_PHONE_API chưa được thiết lập trong .env\")\n",
        "\n",
        "    url = \"https://phonevalidation.abstractapi.com/v1/\"\n",
        "    normalized_phone = normalize_phone_vn(phone)\n",
        "    params = {\n",
        "        \"api_key\": api_key,\n",
        "        \"phone\": normalized_phone\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Lỗi API: {response.status_code} – {response.text}\")\n",
        "\n",
        "    return response.json()\n",
        "\n",
        "# Hàm phân tích kết quả trả về\n",
        "def parse_phone_result(result):\n",
        "    try:\n",
        "        phone = result.get(\"phone\")\n",
        "        valid = result.get(\"valid\", False)\n",
        "        country = result.get(\"country\", {}).get(\"name\", \"\")\n",
        "        country_code = result.get(\"country\", {}).get(\"code\", \"\")\n",
        "        intl_format = result.get(\"format\", {}).get(\"international\", \"\")\n",
        "        local_format = result.get(\"format\", {}).get(\"local\", \"\")\n",
        "\n",
        "        is_foreign = country and country != \"Vietnam\"\n",
        "        is_high_risk = country in SUSPICIOUS_COUNTRIES\n",
        "\n",
        "        return {\n",
        "            \"phone\": phone,\n",
        "            \"valid\": valid,\n",
        "            \"international_format\": intl_format,\n",
        "            \"local_format\": local_format,\n",
        "            \"country\": country,\n",
        "            \"country_code\": country_code,\n",
        "            \"location\": result.get(\"location\"),\n",
        "            \"carrier\": result.get(\"carrier\"),\n",
        "            \"type\": result.get(\"type\"),\n",
        "            \"is_foreign_number\": is_foreign,\n",
        "            \"is_high_risk_country\": is_high_risk,\n",
        "            \"conclusion\": (\n",
        "                \"Không hợp lệ\" if not valid else\n",
        "                \"Số từ quốc gia rủi ro (cần cẩn trọng)\" if is_high_risk else\n",
        "                \"Số từ nước ngoài\" if is_foreign else\n",
        "                \"Số hợp lệ nội địa\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": f\"Lỗi phân tích dữ liệu số điện thoại: {e}\"\n",
        "        }\n",
        "\n",
        "def build_checks_summary(url=None, email=None, phone=None):\n",
        "    parts = []\n",
        "\n",
        "    if url:\n",
        "        url_result = check_url_virustotal(url)\n",
        "        check_url = parse_vt_result_for_display(url_result)\n",
        "        parts.append(f\"Kết quả kiểm tra URL: {check_url}\")\n",
        "\n",
        "    if email:\n",
        "        mail_result = check_email_validity(email)\n",
        "        check_mail = parse_email_result(mail_result)\n",
        "        parts.append(f\"Kết quả kiểm tra Mail: {check_mail}\")\n",
        "\n",
        "    if phone:\n",
        "        phone_result = check_phone_validity(phone)\n",
        "        check_phone = parse_phone_result(phone_result)\n",
        "        parts.append(f\"Kết quả kiểm tra Phone: {check_phone}\")\n",
        "\n",
        "    return parts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7nGgsSc1kya"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqYR0JbnUx4R"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"unsloth/gemma-3-4b-it\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X83DHf8eYFzp"
      },
      "outputs": [],
      "source": [
        "prompt = \"Bạn đã trúng thưởng 1 chiếc Iphone 16, hãy nhấn vào link để nhận thưởng\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Bạn là 1 AI thông minh hỗ trợ phân loại tin tức real và fake. Hãy phân loại tin tức người dùng thuộc loại real hoặc fake. Nhớ chỉ cần trả lời đúng là real hoặc fake không cần giải thích thêm\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFoXahIFYH16"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=512\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpDArBoYMeZ"
      },
      "source": [
        "## Finetune model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7qMoDITYOtZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dữ liệu\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "val_df   = pd.read_csv(\"/content/val.csv\")\n",
        "\n",
        "train_df = train_df[[\"text\", \"label\"]]\n",
        "val_df   = val_df[[\"text\", \"label\"]]\n",
        "\n",
        "# Định dạng instruction-style (prompt/response)\n",
        "def format_supervised(example):\n",
        "    return {\n",
        "        \"prompt\": f\"Phân loại tin tức sau là real hay fake:\\n\\n{example['text']}\",\n",
        "        \"response\": example[\"label\"],\n",
        "    }\n",
        "\n",
        "train_data = train_df.apply(format_supervised, axis=1).to_list()\n",
        "val_data   = val_df.apply(format_supervised, axis=1).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G6PK-ynaq4x",
        "outputId": "b8b74c91-2117-4d9a-a310-499d219b1c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.5.7: Fast Gemma3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Making `model.base_model.model.language_model.model` require gradients\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3-4b-it\",\n",
        "    max_seq_length = 1024,\n",
        "    load_in_4bit = True,  # giảm RAM cho Colab free\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "# Cấu hình LoRA\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8,\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        "    # target_modules = [\"q_proj\", \"v_proj\"],  # dùng mặc định\n",
        "    target_modules=['o_proj', 'qkv_proj', 'gate_up_proj', 'down_proj'],\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing=False,\n",
        "    random_state = 42,\n",
        "    use_rslora = False,\n",
        "    loftq_config=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxMb6dfvarUB"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def convert_to_prompt(row):\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\nPhân loại tin tức sau là real hay fake:\\n\\n{row['text']}\\n\\n### Response:\\n{row['label']}\"\n",
        "    }\n",
        "\n",
        "# Áp dụng cho từng bộ dữ liệu\n",
        "train_dataset = Dataset.from_pandas(train_df.apply(convert_to_prompt, axis=1, result_type=\"expand\"))\n",
        "val_dataset   = Dataset.from_pandas(val_df.apply(convert_to_prompt, axis=1, result_type=\"expand\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRgx2PE3fNIB"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir = \"Gemma3-lora-output\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        per_device_eval_batch_size = 2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs = 3,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 10,\n",
        "        eval_steps=50,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=50,\n",
        "        optim=\"adamw_8bit\",\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        fp16 = True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g38cjPAMDM0H"
      },
      "source": [
        "### Gemma3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "qE7aZ_c4DOfu",
        "outputId": "313354d4-a72f-4d90-8bd6-a9aa0027da57"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    formatting_func = lambda example: [example[\"text\"]],\n",
        "    max_seq_length=2048,\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "692_d7KWDQo1"
      },
      "outputs": [],
      "source": [
        "trainer.model.save_pretrained(\"Gemma3-lora-news\")\n",
        "tokenizer.save_pretrained(\"Gemma3-lora-news\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKKyw3ZwuDeq"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OD6UFoPoS0C"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"qwen2.5_finetuned\",\n",
        "    max_seq_length = 1024,\n",
        "    load_in_4bit = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHk1GQeKpi9K"
      },
      "outputs": [],
      "source": [
        "prompt = \"Phân loại tin tức sau là real hay fake:\\n\\nBạn đã trúng thưởng giải Jackpot trị giá 1 tỷ đồng tại https://www.x311y.com/. Nhấn vào link để nhận ngay\\n\\n### Response:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "print(\"Kết luận:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SioQ_4xp097"
      },
      "source": [
        "## Test model after finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAptXnzXfzl3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Load model (Qwen fine-tuned)\n",
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Gemma3-lora-news\",\n",
        "    max_seq_length = 1024,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "def extract_contact_info(text: str) -> str:\n",
        "    email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
        "    url_pattern = r\"https?://[^\\s]+|www\\.[^\\s]+\"\n",
        "    phone_pattern = r\"(\\+?84|0)?\\s?(\\d{9,10})\"\n",
        "\n",
        "    email = ''\n",
        "    phone = ''\n",
        "    url = ''\n",
        "\n",
        "    email_match = re.search(email_pattern, text)\n",
        "    if email_match:\n",
        "        email = email_match.group(0)\n",
        "    \n",
        "    # Tìm URL đầu tiên\n",
        "    url_match = re.search(url_pattern, text)\n",
        "    if url_match:\n",
        "        url = url_match.group(0)\n",
        "    \n",
        "    # Tìm số điện thoại đầu tiên\n",
        "    phone_match = re.search(phone_pattern, text)\n",
        "    if phone_match:\n",
        "        phone = \"\".join([g if g is not None else \"\" for g in phone_match.groups()]) if phone_match else \"\"\n",
        "\n",
        "    return email, phone, url\n",
        "\n",
        "def classify_news(input_text: str, check_summary: list) -> str:\n",
        "    joined_check = \"\\n\".join(check_summary)\n",
        "    full_prompt = f\"\"\"Bạn là trợ lý AI có nhiệm vụ xác thực tin tức là real hay fake.\n",
        "\n",
        "    Thông tin cần xác thực: {input_text}\n",
        "\n",
        "    Kết quả kiểm tra bổ sung (nếu có):\n",
        "    {joined_check}\n",
        "\n",
        "    Yêu cầu:\n",
        "    Chỉ trả lời duy nhất 1 trong 2 từ sau: real hoặc fake.\n",
        "    Không thêm giải thích, không ghi chú, không dòng thừa.\n",
        "\n",
        "\n",
        "    Kết luận:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "    return response.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvkJebRXgbDv"
      },
      "outputs": [],
      "source": [
        "# ==== TEST ====\n",
        "input_text = \"Chính phủ ra lệnh cấm sử dụng mạng xã hội Facebook tại Việt Nam từ tháng sau\"\n",
        "email, phone, url = extract_contact_info(input_text)\n",
        "\n",
        "check_summary = build_checks_summary(url, email, phone)\n",
        "# print(\"Check Summary:\", check_summary)\n",
        "\n",
        "final_label = classify_news(input_text, check_summary)\n",
        "print(\"\\n🧠 Kết luận cuối cùng:\", final_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOB98Abgh9fv"
      },
      "source": [
        "## Testing with test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYDi9s2Vh9wH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df = pd.read_csv('/content/test.csv')\n",
        "llm_outputs = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    input_text = row['text']\n",
        "\n",
        "    try:\n",
        "        email, phone, url = extract_contact_info(input_text)\n",
        "        check_summary = build_checks_summary(url, email, phone)\n",
        "        # Phân loại\n",
        "        final_label = classify_news(input_text, check_summary)\n",
        "        llm_outputs.append(final_label)\n",
        "        print(\"Kết luận:\", final_label)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error: {str(e)}\"\n",
        "        llm_outputs.append(error_msg)\n",
        "        print(\"❌ Lỗi xử lý:\", error_msg)\n",
        "\n",
        "# Ghi kết quả vào cột mới và lưu file\n",
        "df['Gemma3_4B_finetuned'] = llm_outputs\n",
        "df.to_csv('test_output_Gemma3_4B_finetuned.csv', index=False)\n",
        "\n",
        "print(\"\\nĐã xử lý xong toàn bộ test.csv và lưu kết quả.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mxXnvoP0xqF6",
        "A7nGgsSc1kya",
        "D2RdfFEpwjQG",
        "0M006OScwmJX",
        "g38cjPAMDM0H",
        "zKKyw3ZwuDeq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
